Refer this playlist => https://www.youtube.com/playlist?list=PLLz6Bi1mIXhHKA1Szy2aj9Jbs6nw9fhNY

1. Create a virtual environment using python3 -m venv venv
2. Activate the virtual environment using ./venc/scripts/activate
3. Install django using pip install django
4. Install celery using pip install celery
5. pip freeze > requirements.txt
6. Create a project using django-admin startproject project_name .
7. Create an app using django-admin startapp app_name
8. Go to settings.py and add the app to installed apps.
9. Search "redis windows github" and go to "https://github.com/tporadowski/redis/releases" and download and install redis.
10. Go to "C:\Program Files\Redis" and run "redis-cli.exe". This will open a redis client. Type "ping" and press enter. If you get "PONG" then you have successfully installed redis.
11. Now add celery settings to settings.py
"
# CELERY SETTINGS

CELERY_BROKER_URL = 'redis://127.0.0.1:6379' #! 6379 is the default port.
CELERY_ACCEPT_CONTENT = ['application/json']
CELERY_RESULT_SERIALIZER = 'json'
CELERY_TASK_SERIALIZER = 'json'
CELERY_TIMEZONE = 'Asia/Kolkata'
"
12. Now create a celery.py file in the project root directory and add the following code.
"
from __future__ import absolute_import, unicode_literals
import os

from celery import Celery
from django.conf import settings
from celery.schedules import crontab

os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'django_celery_project.settings')

app = Celery('django_celery_project')
app.conf.enable_utc = False #! By default celery has enabled utc timezone, disable it for this project so that we can use Asia/Kolkata timezone.

app.conf.update(timezone = 'Asia/Kolkata')

app.config_from_object(settings, namespace='CELERY')

# Celery Beat Settings

app.autodiscover_tasks()

@app.task(bind=True)
def debug_task(self):
    print(f'Request: {self.request!r}')
"
13. Now create a tasks.py file in the app directory and add the following code. This is where we will write all the celery tasks specific to that app. You can create tasks.py for any app.
"
from celery import shared_task

@shared_task(bind=True)
def test_func(self):
    #operations
    for i in range(10):
        print(i)
    return "Done"
"
14. Install redis using pip intall redis
15. Setup urls.py for both project and app.
16. Now run the celery worker from terminal using "celery -A django_celery_project.celery worker --pool=solo -l info"

Output after running the celery worker command =>
"
(venv) PS D:\celery_with_django> celery -A django_celery_project.celery worker --pool=solo -l info
 
 -------------- celery@LTCZ0258 v5.3.6 (emerald-rush)
--- ***** ----- 
-- ******* ---- Windows-10-10.0.19045-SP0 2024-01-27 20:00:00
- *** --- * --- 
- ** ---------- [config]
- ** ---------- .> app:         django_celery_project:0x21908eeec50
- ** ---------- .> transport:   redis://127.0.0.1:6379//
- ** ---------- .> results:     disabled://
- *** --- * --- .> concurrency: 12 (solo)
-- ******* ---- .> task events: OFF (enable -E to monitor tasks in this worker)
--- ***** ----- 
 -------------- [queues]
                .> celery           exchange=celery(direct) key=celery


[tasks]
  . django_celery_project.celery.debug_task
  . mainapp.tasks.test_func

[2024-01-27 20:00:00,096: WARNING/MainProcess] D:\celery_with_django\venv\Lib\site-packages\celery\app\utils.py:203: CDeprecationWarning:
    The 'CELERY_TIMEZONE' setting is deprecated and scheduled for removal in        
    version 6.0.0. Use the timezone instead

  deprecated.warn(description=f'The {setting!r} setting',

[2024-01-27 20:00:00,097: WARNING/MainProcess] D:\celery_with_django\venv\Lib\site-packages\celery\app\utils.py:203: CDeprecationWarning:
    The 'CELERY_ACCEPT_CONTENT' setting is deprecated and scheduled for removal in  
    version 6.0.0. Use the accept_content instead

  deprecated.warn(description=f'The {setting!r} setting',

[2024-01-27 20:00:00,098: WARNING/MainProcess] D:\celery_with_django\venv\Lib\site-packages\celery\app\utils.py:203: CDeprecationWarning:
    The 'CELERY_TASK_SERIALIZER' setting is deprecated and scheduled for removal in 
    version 6.0.0. Use the task_serializer instead

  deprecated.warn(description=f'The {setting!r} setting',

[2024-01-27 20:00:00,098: WARNING/MainProcess] D:\celery_with_django\venv\Lib\site-packages\celery\app\utils.py:203: CDeprecationWarning:
    The 'CELERY_RESULT_SERIALIZER' setting is deprecated and scheduled for removal in
    version 6.0.0. Use the result_serializer instead

  deprecated.warn(description=f'The {setting!r} setting',

[2024-01-27 20:00:00,099: WARNING/MainProcess] Please run `celery upgrade settings path/to/settings.py` to avoid these warnings and to allow a smoother upgrade to Celery 6.0.
[2024-01-27 20:00:00,102: WARNING/MainProcess] D:\celery_with_django\venv\Lib\site-packages\celery\worker\consumer\consumer.py:507: CPendingDeprecationWarning: The broker_connection_retry 
configuration setting will no longer determine
whether broker connection retries are made during startup in Celery 6.0 and above.
If you wish to retain the existing behavior for retrying connections on startup,
you should set broker_connection_retry_on_startup to True.
  warnings.warn(

[2024-01-27 20:00:00,108: INFO/MainProcess] Connected to redis://127.0.0.1:6379//
[2024-01-27 20:00:00,109: WARNING/MainProcess] D:\celery_with_django\venv\Lib\site-packages\celery\worker\consumer\consumer.py:507: CPendingDeprecationWarning: The broker_connection_retry 
configuration setting will no longer determine
whether broker connection retries are made during startup in Celery 6.0 and above.
If you wish to retain the existing behavior for retrying connections on startup,
you should set broker_connection_retry_on_startup to True.
  warnings.warn(

[2024-01-27 20:00:00,112: INFO/MainProcess] mingle: searching for neighbors
[2024-01-27 20:00:01,128: INFO/MainProcess] mingle: all alone
[2024-01-27 20:00:01,143: INFO/MainProcess] celery@LTCZ0258 ready.
"

How to fix these deprecated warnings?
"
CELERY_TIMEZONE:
Replace CELERY_TIMEZONE with timezone. You've already done this in your code, so no action is needed here.

CELERY_ACCEPT_CONTENT:
Replace CELERY_ACCEPT_CONTENT with accept_content.

CELERY_TASK_SERIALIZER:
Replace CELERY_TASK_SERIALIZER with task_serializer.

CELERY_RESULT_SERIALIZER:
Replace CELERY_RESULT_SERIALIZER with result_serializer.

Additionally, you're advised to run celery upgrade settings path/to/settings.py to ensure a smoother upgrade to Celery 6.0 and to avoid these warnings in the future.
"

17. To view the status of your tasks, first add this to your settings.py file "CELERY_RESULT_BACKEND = 'django-db'". This will store the results in the database.
18. Then Install django-celery-results using pip install django-celery-results
19. Now add django_celery_results to installed apps.
20. Now run "python manage.py makemigrations" and "python manage.py migrate" to create the database tables.
21. Now add the following to your __init__.py file in your project folder
"
from .celery import app as celery_app

__all__ = ('celery_app',)
"
22. Now run the celery worker again using "celery -A django_celery_project.celery worker --pool=solo -l info" and your django server using "python manage.py runserver"

23. In the celery server terminal, you should see the following output =>
"
[2024-01-27 20:25:32,287: INFO/MainProcess] mingle: searching for neighbors
[2024-01-27 20:25:33,291: INFO/MainProcess] mingle: all alone
[2024-01-27 20:25:33,310: INFO/MainProcess] celery@LTCZ0258 ready.
[2024-01-27 20:26:13,423: INFO/MainProcess] Task mainapp.tasks.test_func[68fd68a2-576c-4a9f-8db8-99095c09a2a7] received
[2024-01-27 20:26:13,424: WARNING/MainProcess] 0
[2024-01-27 20:26:13,424: WARNING/MainProcess] 1
[2024-01-27 20:26:13,424: WARNING/MainProcess] 2
[2024-01-27 20:26:13,424: WARNING/MainProcess] 3
[2024-01-27 20:26:13,425: WARNING/MainProcess] 4
[2024-01-27 20:26:13,425: WARNING/MainProcess] 5
[2024-01-27 20:26:13,425: WARNING/MainProcess] 6
[2024-01-27 20:26:13,425: WARNING/MainProcess] 7
[2024-01-27 20:26:13,425: WARNING/MainProcess] 8
[2024-01-27 20:26:13,425: WARNING/MainProcess] 9
[2024-01-27 20:26:13,442: INFO/MainProcess] Task mainapp.tasks.test_func[68fd68a2-576c-4a9f-8db8-99095c09a2a7] succeeded in 0.01600000000325963s: 'Done'
"
24. In your db.sqlite3, go to the table "django_celery_results_taskresult" and you should see the outcome of your task.

#TODO: Read the comments added to the view.py to understand what exactly happened.


25. Here in the view, django didn't perform the task and returned the return message as soon the task was called when the view was invoked, it didn't wait for the task to complete.
26. To fix this, we need to use the .wait() to tell django to wait for the task to complete before returning the response and use this code in view.py file =>
"
def test(request):
    # Execute the task asynchronously
    task_result = test_func.delay()

    # Wait for the task to complete
    task_result.wait()

    # Check if the task completed successfully
    if task_result.successful():
        # If the task has completed successfully, return "Done"
        return HttpResponse("Done")
    else:
        # If the task has failed, return an error message
        return HttpResponse("Task failed. Please try again later.")

"


#TODO: READ THIS
"

In Celery, both @shared_task and @task are decorators used to define tasks, but they have different behaviors and use cases:

@shared_task:

@shared_task is a decorator provided by Celery that creates a task without a specific instance of a Celery application.
It's often used when you want to define tasks independently of any particular Celery application instance.
This is useful when you have a reusable task that you want to define in a separate module or library without directly referencing a Celery application instance.
When using @shared_task, you typically need to provide the Celery application instance when you want to use the task. This can be done using the app parameter of the task decorator or by importing the task into your application and then using it with the application's Celery instance.
@task:

@task is a decorator provided by Celery that creates a task associated with a specific Celery application instance.
It's used when you have a task that's tightly coupled with a particular Celery application instance.
Tasks decorated with @task are automatically registered with the associated Celery application.
This decorator is suitable when you're defining tasks within the context of a specific Celery application and want them to be automatically discovered and registered by that application.
You don't need to explicitly provide the Celery application instance when using tasks decorated with @task.
"
27. Create a superuser using "python manage.py createsuperuser"
28. Now we will add django-celery-beat to our project which will help us to schedule our tasks.
29. Install django-celery-beat using pip install django-celery-beat
30. Now add django_celery_beat to installed apps in settings.py file.
31. Now add celery beat settings to settings.py file. => CELERY_BEAT_SCHEDULER = 'django_celery_beat.schedulers:DatabaseScheduler'
32. Now again run "python manage.py makemigrations" and "python manage.py migrate" to create the database tables.
32. Now activate celery beat in the terminal using "celery -A django_celery_project beat -l info"